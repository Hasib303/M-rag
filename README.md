# Multilingual RAG System

A comprehensive Retrieval-Augmented Generation (RAG) system designed for Bengali and English text processing. This system uses OCR-based PDF text extraction, intelligent text chunking, vector embeddings, and GPT-4 for accurate question answering.

## ğŸš€ Features

- **Multilingual Support**: Bengali and English text processing
- **OCR-based PDF Extraction**: Advanced text extraction using EasyOCR for better Bengali text recognition
- **Intelligent Text Chunking**: Smart document segmentation with configurable overlap
- **Vector Database**: Pinecone integration for efficient semantic search
- **OpenAI Integration**: GPT-4 powered query processing with context-aware responses
- **REST API**: Comprehensive FastAPI-based endpoints for all functionality
- **Modular Architecture**: Clean separation of concerns with individual service modules

## ğŸ“‹ Table of Contents

- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
- [Project Structure](#project-structure)
- [Examples](#examples)
- [Contributing](#contributing)

## ğŸ›  Installation

### Prerequisites

- Python 3.8+
- OpenAI API Key
- Pinecone API Key
- Virtual Environment (recommended)

### Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd "Multilingual RAG"
   ```

2. **Create and activate virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

## âš™ï¸ Configuration

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX=multilingual-rag
```

## ğŸš¦ Usage

### Quick Start

1. **Start the API server**
   ```bash
   uvicorn api:app --reload
   ```

2. **Access the interactive documentation**
   - Open: `http://localhost:8000/docs`
   - Alternative docs: `http://localhost:8000/redoc`

3. **Process a PDF document**
   ```bash
   curl -X POST "http://localhost:8000/api/rag-system/process-pdf" \
     -H "Content-Type: application/json" \
     -d '{"pdf_path": "data/HSC26-Bangla1st-Paper.pdf"}'
   ```

4. **Ask a question**
   ```bash
   curl -X POST "http://localhost:8000/api/chatbot/query" \
     -H "Content-Type: application/json" \
     -d '{"question": "à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?"}'
   ```

### Command Line Interface

Run the interactive CLI:
```bash
python main.py
```

## ğŸ“¡ API Endpoints

All endpoints are prefixed with `/api` and organized by functionality:

### Chatbot
- `POST /api/chatbot/query` - Main question-answering endpoint

### RAG System
- `POST /api/rag-system/process-pdf` - Process PDF into vector database
- `POST /api/rag-system/query` - Query with context retrieval
- `POST /api/rag-system/query-with-sources` - Query with source attribution
- `GET /api/rag-system/health` - System health check

### PDF Processing
- `POST /api/pdf-extractor/extract-pdf` - Extract text with page breakdown
- `POST /api/pdf-extractor/extract-pdf-text` - Extract as single text string

### Text Processing
- `POST /api/text-chunker/chunk-text` - Split text into chunks
- `POST /api/text-chunker/chunk-documents` - Split documents into chunks

### Embeddings
- `POST /api/embeddings/embed-text` - Generate single text embedding
- `POST /api/embeddings/embed-texts` - Generate multiple text embeddings

### Vector Database
- `POST /api/vector-store/add-documents` - Add documents to vector store
- `POST /api/vector-store/search` - Search similar documents
- `POST /api/vector-store/search-with-scores` - Search with similarity scores

### Query Processing
- `POST /api/query-processor/process-query` - Process query with context
- `GET /api/query-processor/chat-history` - Get chat history
- `DELETE /api/query-processor/clear-history` - Clear chat history

## ğŸ“ Project Structure

```
Multilingual RAG/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py          # OpenAI embeddings service
â”‚   â”œâ”€â”€ pdf_extractor.py       # OCR-based PDF text extraction
â”‚   â”œâ”€â”€ query_processor.py     # GPT-4 query processing
â”‚   â”œâ”€â”€ rag_system.py         # Main RAG orchestrator
â”‚   â”œâ”€â”€ text_chunker.py       # Text chunking utilities
â”‚   â”œâ”€â”€ vector_store.py       # Pinecone vector database
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ all_routes.py     # All API endpoints
â”œâ”€â”€ data/
â”‚   â””â”€â”€ HSC26-Bangla1st-Paper.pdf  # Sample Bengali PDF
â”œâ”€â”€ api.py                    # FastAPI application
â”œâ”€â”€ main.py                   # CLI interface
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env.example             # Environment variables template
â””â”€â”€ README.md                # This file
```

## ğŸ“– Examples

### Processing Bengali Questions

```python
import requests

# Process a PDF
response = requests.post(
    "http://localhost:8000/api/rag-system/process-pdf",
    json={"pdf_path": "data/HSC26-Bangla1st-Paper.pdf"}
)

# Ask a Bengali question
response = requests.post(
    "http://localhost:8000/api/chatbot/query",
    json={"question": "à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?"}
)

print(response.json())
# Output: {"answer": "à¦¶à§à¦®à§à¦­à§à¦¨à¦¾à¦¥"}
```

### Embedding Generation

```python
# Generate embedding for Bengali text
response = requests.post(
    "http://localhost:8000/api/embeddings/embed-text",
    json={"text": "à¦¬à¦¾à¦‚à¦²à¦¾ à¦­à¦¾à¦·à¦¾"}
)

embedding = response.json()["embedding"]  # List of 1536 floats
```

### Document Chunking

```python
# Chunk a large document
response = requests.post(
    "http://localhost:8000/api/text-chunker/chunk-text",
    json={
        "text": "Your large text document here...",
        "chunk_size": 500,
        "chunk_overlap": 100
    }
)

chunks = response.json()["chunks"]
```

## ğŸ”§ Key Components

### PDF Extractor
- Uses `pdf2image` to convert PDF pages to images
- Employs `EasyOCR` with Bengali language support
- Fallback to PyPDF for standard text extraction

### Text Chunker
- Recursive character-based text splitting
- Configurable chunk size and overlap
- Preserves document metadata

### Vector Store
- Pinecone integration for scalable vector search
- Automatic index creation and management
- Similarity search with configurable results count

### Query Processor
- GPT-4 powered natural language processing
- Context-aware response generation
- Chat history management
- Bilingual prompt engineering

## ğŸ¯ Use Cases

- **Educational Content Analysis**: Process Bengali textbooks and answer questions
- **Document Q&A**: Extract information from multilingual PDFs
- **Research Assistant**: Semantic search through academic papers
- **Content Management**: Organize and query large document collections

## âš¡ Performance Optimization

- **Caching**: Efficient embedding caching for repeated queries
- **Chunking Strategy**: Optimized chunk sizes for Bengali text
- **Vector Search**: Fast similarity search with Pinecone
- **OCR Processing**: Parallel page processing for large PDFs

## ğŸ› Troubleshooting

### Common Issues

1. **Pinecone Connection Errors**
   - Verify API key is correct
   - Check index name exists
   - Ensure proper network connectivity

2. **OCR Extraction Issues**
   - Install system dependencies for pdf2image
   - Check PDF file permissions
   - Verify EasyOCR model downloads

3. **Memory Issues with Large PDFs**
   - Process PDFs in batches
   - Adjust chunk sizes
   - Monitor system resources

## ğŸ“Š System Requirements

- **RAM**: Minimum 4GB, Recommended 8GB+
- **Storage**: 2GB for models and dependencies
- **Network**: Stable internet for API calls
- **OS**: Linux, macOS, or Windows

## ğŸ”’ Security Considerations

- Store API keys securely in environment variables
- Implement rate limiting for production use
- Validate file uploads and paths
- Monitor API usage and costs

## ğŸ“ˆ Future Enhancements

- [ ] Support for more languages
- [ ] Advanced document preprocessing
- [ ] Custom embedding models
- [ ] Real-time document updates
- [ ] Authentication and authorization
- [ ] Metrics and monitoring dashboard

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For questions, issues, or contributions:
- Create an issue in the repository
- Check the documentation at `/docs`
- Review the API documentation at `/api/docs`

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 and embedding models
- Pinecone for vector database services
- LangChain for RAG framework
- EasyOCR for multilingual OCR capabilities
- FastAPI for the web framework

---

**Built with â¤ï¸ for multilingual text processing**